{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","### In this notebook we use [PointNet](https://arxiv.org/abs/1612.00593) to perform 3D Object Classification on [ModelNet10 Dataset](http://modelnet.cs.princeton.edu/#)."]},{"cell_type":"markdown","metadata":{},"source":["<h3><center>Applications of PointNet</center></h3>\n","<img src=\"http://stanford.edu/~rqi/pointnet/images/teaser.jpg\" width=\"600\" height=\"500\"/>\n","<h4></h4>\n","<h4><center><a href=\"https://arxiv.org/pdf/1612.00593.pdf\">Source: PointNet [Charles R. Qi et. al.]</a></center></h4>"]},{"cell_type":"markdown","metadata":{},"source":["## Acknowledgements\n","\n","### This work was inspired by and borrows code from [Nikita Karaev's](https://github.com/nikitakaraevv) [PointNet implementation](https://github.com/nikitakaraevv/pointnet)."]},{"cell_type":"markdown","metadata":{},"source":["### Libraries üìö‚¨á"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import itertools\n","import math, random\n","random.seed = 42\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","\n","from pathlib import Path\n","import scipy.spatial.distance\n","import plotly.graph_objects as go\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/dmitry/.kaggle/kaggle.json'\n","Downloading modelnet10-princeton-3d-object-dataset.zip to /home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D\n"," 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 112M/454M [00:10<00:30, 11.6MB/s]^C\n"," 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 113M/454M [00:10<00:32, 11.0MB/s]\n","User cancelled operation\n"]}],"source":["!kaggle datasets download -d balraj98/modelnet10-princeton-3d-object-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import zipfile\n","\n","with zipfile.ZipFile(\"modelnet10-princeton-3d-object-dataset.zip\", mode=\"r\") as data:\n","     data.extractall()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["os.remove(\"modelnet10-princeton-3d-object-dataset.zip\")"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["{'bathtub': 0,\n"," 'bed': 1,\n"," 'chair': 2,\n"," 'desk': 3,\n"," 'dresser': 4,\n"," 'monitor': 5,\n"," 'night_stand': 6,\n"," 'sofa': 7,\n"," 'table': 8,\n"," 'toilet': 9}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["path = Path(\"ModelNet10\")\n","\n","folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n","classes = {folder: i for i, folder in enumerate(folders)};\n","classes"]},{"cell_type":"markdown","metadata":{},"source":["### Utility Functions"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["def read_off(file):\n","    if 'OFF' != file.readline().strip():\n","        raise('Not a valid OFF header')\n","    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n","    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n","    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n","    return verts, faces\n","\n","\n","def visualize_rotate(data):\n","    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n","    frames=[]\n","\n","    def rotate_z(x, y, z, theta):\n","        w = x+1j*y\n","        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n","\n","    for t in np.arange(0, 10.26, 0.1):\n","        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n","        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n","    fig = go.Figure(data=data,\n","        layout=go.Layout(\n","            updatemenus=[dict(type='buttons',\n","                showactive=False,\n","                y=1,\n","                x=0.8,\n","                xanchor='left',\n","                yanchor='bottom',\n","                pad=dict(t=45, r=10),\n","                buttons=[dict(label='Play',\n","                    method='animate',\n","                    args=[None, dict(frame=dict(duration=50, redraw=True),\n","                        transition=dict(duration=0),\n","                        fromcurrent=True,\n","                        mode='immediate'\n","                        )]\n","                    )\n","                ])]\n","        ),\n","        frames=frames\n","    )\n","\n","    return fig\n","\n","\n","def pcshow(xs,ys,zs):\n","    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n","                                   mode='markers')]\n","    fig = visualize_rotate(data)\n","    fig.update_traces(marker=dict(size=2,\n","                      line=dict(width=2,\n","                      color='DarkSlateGrey')),\n","                      selector=dict(mode='markers'))\n","    fig.show()"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["6433"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["with open(path/\"sofa/train/sofa_0002.off\", 'r') as f:\n","    verts, faces = read_off(f)\n","    \n","i,j,k = np.array(faces).T\n","x,y,z = np.array(verts).T\n","len(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='yellowgreen', opacity=0.50, i=i,j=j,k=k)]).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["visualize_rotate([go.Scatter3d(x=x, y=y, z=z, mode='markers')]).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pcshow(x,y,z)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["class PointSampler(object):\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, int)\n","        self.output_size = output_size\n","    \n","    def triangle_area(self, pt1, pt2, pt3):\n","        side_a = np.linalg.norm(pt1 - pt2)\n","        side_b = np.linalg.norm(pt2 - pt3)\n","        side_c = np.linalg.norm(pt3 - pt1)\n","        s = 0.5 * ( side_a + side_b + side_c)\n","        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n","\n","    def sample_point(self, pt1, pt2, pt3):\n","        # barycentric coordinates on a triangle\n","        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n","        s, t = sorted([random.random(), random.random()])\n","        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n","        return (f(0), f(1), f(2))\n","        \n","    \n","    def __call__(self, mesh):\n","        verts, faces = mesh\n","        verts = np.array(verts)\n","        areas = np.zeros((len(faces)))\n","\n","        for i in range(len(areas)):\n","            areas[i] = (self.triangle_area(verts[faces[i][0]],\n","                                           verts[faces[i][1]],\n","                                           verts[faces[i][2]]))\n","            \n","        sampled_faces = (random.choices(faces, \n","                                      weights=areas,\n","                                      cum_weights=None,\n","                                      k=self.output_size))\n","        \n","        sampled_points = np.zeros((self.output_size, 3))\n","\n","        for i in range(len(sampled_faces)):\n","            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n","                                                   verts[sampled_faces[i][1]],\n","                                                   verts[sampled_faces[i][2]]))\n","        \n","        return sampled_points"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pointcloud = PointSampler(3000)((verts, faces))\n","pcshow(*pointcloud.T)"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["class Normalize(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","        \n","        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n","        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n","\n","        return  norm_pointcloud"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["norm_pointcloud = Normalize()(pointcloud)\n","pcshow(*norm_pointcloud.T)"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["class RandRotation_z(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        theta = random.random() * 2. * math.pi\n","        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n","                               [ math.sin(theta),  math.cos(theta),    0],\n","                               [0,                             0,      1]])\n","        \n","        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n","        return  rot_pointcloud\n","    \n","class RandomNoise(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n","    \n","        noisy_pointcloud = pointcloud + noise\n","        return  noisy_pointcloud"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rot_pointcloud = RandRotation_z()(norm_pointcloud)\n","noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)\n","pcshow(*noisy_rot_pointcloud.T)"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["class ToTensor(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        return torch.from_numpy(pointcloud)"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["def default_transforms():\n","    return transforms.Compose([\n","                                PointSampler(1024),\n","                                Normalize(),\n","                                ToTensor()\n","                              ])"]},{"cell_type":"markdown","metadata":{},"source":["### Define Datasets / Dataloaders"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["class PointCloudData(Dataset):\n","    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n","        self.root_dir = root_dir\n","        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n","        self.classes = {folder: i for i, folder in enumerate(folders)}\n","        self.transforms = transform if not valid else default_transforms()\n","        self.valid = valid\n","        self.files = []\n","        for category in self.classes.keys():\n","            new_dir = root_dir/Path(category)/folder\n","            for file in os.listdir(new_dir):\n","                if file.endswith('.off'):\n","                    sample = {}\n","                    sample['pcd_path'] = new_dir/file\n","                    sample['category'] = category\n","                    self.files.append(sample)\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __preproc__(self, file):\n","        verts, faces = read_off(file)\n","        if self.transforms:\n","            pointcloud = self.transforms((verts, faces))\n","        return pointcloud\n","\n","    def __getitem__(self, idx):\n","        pcd_path = self.files[idx]['pcd_path']\n","        category = self.files[idx]['category']\n","        with open(pcd_path, 'r') as f:\n","            pointcloud = self.__preproc__(f)\n","        return {'pointcloud': pointcloud, \n","                'category': self.classes[category]}"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["train_transforms = transforms.Compose([\n","                    PointSampler(1024),\n","                    Normalize(),\n","                    RandRotation_z(),\n","                    RandomNoise(),\n","                    ToTensor()\n","                    ])"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["train_ds = PointCloudData(path, transform=train_transforms)\n","valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["{0: 'bathtub',\n"," 1: 'bed',\n"," 2: 'chair',\n"," 3: 'desk',\n"," 4: 'dresser',\n"," 5: 'monitor',\n"," 6: 'night_stand',\n"," 7: 'sofa',\n"," 8: 'table',\n"," 9: 'toilet'}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["inv_classes = {i: cat for cat, i in train_ds.classes.items()};\n","inv_classes"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset size:  3991\n","Valid dataset size:  908\n","Number of classes:  10\n","Sample pointcloud shape:  torch.Size([1024, 3])\n","Class:  bathtub\n"]}],"source":["print('Train dataset size: ', len(train_ds))\n","print('Valid dataset size: ', len(valid_ds))\n","print('Number of classes: ', len(train_ds.classes))\n","print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n","print('Class: ', inv_classes[train_ds[0]['category']])"]},{"cell_type":"code","execution_count":76,"metadata":{"trusted":true},"outputs":[],"source":["train_loader = DataLoader(dataset=train_ds, batch_size=8, shuffle=True)\n","valid_loader = DataLoader(dataset=valid_ds, batch_size=8)"]},{"cell_type":"markdown","metadata":{},"source":["<h3><center>PointNet Model Architecture</center></h3>\n","<img src=\"http://stanford.edu/~rqi/pointnet/images/pointnet.jpg\" width=\"750\" height=\"750\"/>\n","<h4></h4>\n","<h4><center><a href=\"https://arxiv.org/pdf/1612.00593.pdf\">Source: PointNet [Charles R. Qi et. al.]</a></center></h4>"]},{"cell_type":"markdown","metadata":{},"source":["### Model Definition"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","\n","class Tnet(nn.Module):\n","    def __init__(self, k=3):\n","        super().__init__()\n","        self.k=k\n","        self.conv1 = nn.Conv1d(k,64,1)\n","        self.conv2 = nn.Conv1d(64,128,1)\n","        self.conv3 = nn.Conv1d(128,1024,1)\n","        self.fc1 = nn.Linear(1024,512)\n","        self.fc2 = nn.Linear(512,256)\n","        self.fc3 = nn.Linear(256,k*k)\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(1024)\n","        self.bn4 = nn.BatchNorm1d(512)\n","        self.bn5 = nn.BatchNorm1d(256)\n","\n","\n","    def forward(self, input):\n","        # input.shape == (bs,n,3)\n","        bs = input.size(0)\n","        xb = F.relu(self.bn1(self.conv1(input)))\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","        xb = F.relu(self.bn3(self.conv3(xb)))\n","        pool = nn.MaxPool1d(xb.size(-1))(xb)\n","        flat = nn.Flatten(1)(pool)\n","        xb = F.relu(self.bn4(self.fc1(flat)))\n","        xb = F.relu(self.bn5(self.fc2(xb)))\n","\n","        #initialize as identity\n","        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n","        if xb.is_cuda:\n","            init=init.cuda()\n","        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n","        return matrix\n","\n","\n","class Transform(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.input_transform = Tnet(k=3)\n","        self.feature_transform = Tnet(k=64)\n","        self.conv1 = nn.Conv1d(3,64,1)\n","\n","        self.conv2 = nn.Conv1d(64,128,1)\n","        self.conv3 = nn.Conv1d(128,1024,1)\n","\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(1024)\n","\n","    def forward(self, input):\n","        matrix3x3 = self.input_transform(input)\n","        # batch matrix multiplication\n","        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n","\n","        xb = F.relu(self.bn1(self.conv1(xb)))\n","\n","        matrix64x64 = self.feature_transform(xb)\n","        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n","\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","        xb = self.bn3(self.conv3(xb))\n","        xb = nn.MaxPool1d(xb.size(-1))(xb)\n","        output = nn.Flatten(1)(xb)\n","        return output, matrix3x3, matrix64x64\n","\n","class PointNet(nn.Module):\n","    def __init__(self, classes = 10):\n","        super().__init__()\n","        self.transform = Transform()\n","        self.fc1 = nn.Linear(1024, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, classes)\n","        \n","\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input):\n","        xb, matrix3x3, matrix64x64 = self.transform(input)\n","        xb = F.relu(self.bn1(self.fc1(xb)))\n","        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n","        output = self.fc3(xb)\n","        return self.logsoftmax(output), matrix3x3, matrix64x64"]},{"cell_type":"code","execution_count":78,"metadata":{"trusted":true},"outputs":[],"source":["def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n","    criterion = torch.nn.NLLLoss()\n","    bs=outputs.size(0)\n","    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n","    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n","    if outputs.is_cuda:\n","        id3x3=id3x3.cuda()\n","        id64x64=id64x64.cuda()\n","    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n","    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n","    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"]},{"cell_type":"code","execution_count":79,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":80,"metadata":{"trusted":true},"outputs":[],"source":["pointnet = PointNet()\n","pointnet.to(device);\n","\n","# Load a pre-trained model if it exists\n","#pointnet.load_state_dict(torch.load('../input/pointnet-for-3d-object-classification-pytorch/save.pth'))"]},{"cell_type":"code","execution_count":72,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.00025)"]},{"cell_type":"markdown","metadata":{},"source":["### Train PointNet"]},{"cell_type":"code","execution_count":81,"metadata":{"trusted":true},"outputs":[],"source":["def train(model, train_loader, val_loader=None,  epochs=1):\n","    for epoch in range(epochs): \n","        pointnet.train()\n","        running_loss = 0.0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n","            optimizer.zero_grad()\n","            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n","\n","            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 5 == 4:    # print every 10 mini-batches\n","                print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n","                    (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n","                running_loss = 0.0\n","\n","        pointnet.eval()\n","        correct = total = 0\n","\n","        # validation\n","        if val_loader:\n","            with torch.no_grad():\n","                for data in val_loader:\n","                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n","                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    total += labels.size(0)\n","                    correct += (predicted == labels).sum().item()\n","            val_acc = 100. * correct / total\n","            print('Valid accuracy: %d %%' % val_acc)\n","\n","        # save the model\n","        torch.save(pointnet.state_dict(), \"save.pth\")"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":85,"metadata":{"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(pointnet, train_loader, valid_loader)\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 41\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pointnet\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m i, data \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(train_loader, \u001b[39m0\u001b[39;49m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39;49m data[\u001b[39m'\u001b[39;49m\u001b[39mpointcloud\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\u001b[39m.\u001b[39;49mfloat(), data[\u001b[39m'\u001b[39;49m\u001b[39mcategory\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 41\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m category \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[idx][\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pcd_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     pointcloud \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__preproc__(f)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mpointcloud\u001b[39m\u001b[39m'\u001b[39m: pointcloud, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses[category]}\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 41\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m verts, faces \u001b[39m=\u001b[39m read_off(file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     pointcloud \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms((verts, faces))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pointcloud\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 41\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m areas \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(faces)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(areas)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     areas[i] \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtriangle_area(verts[faces[i][\u001b[39m0\u001b[39;49m]],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                                    verts[faces[i][\u001b[39m1\u001b[39;49m]],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                                    verts[faces[i][\u001b[39m2\u001b[39;49m]]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m sampled_faces \u001b[39m=\u001b[39m (random\u001b[39m.\u001b[39mchoices(faces, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                               weights\u001b[39m=\u001b[39mareas,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                               cum_weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                               k\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m sampled_points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size, \u001b[39m3\u001b[39m))\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 41\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtriangle_area\u001b[39m(\u001b[39mself\u001b[39m, pt1, pt2, pt3):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     side_a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(pt1 \u001b[39m-\u001b[39m pt2)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     side_b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(pt2 \u001b[39m-\u001b[39;49m pt3)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     side_c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(pt3 \u001b[39m-\u001b[39m pt1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     s \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m ( side_a \u001b[39m+\u001b[39m side_b \u001b[39m+\u001b[39m side_c)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/numpy/linalg/linalg.py:2553\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2551\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2552\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdot(x)\n\u001b[0;32m-> 2553\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2554\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   2555\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mreshape(ndim\u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m])\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train(pointnet, train_loader, valid_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Test PointNet"]},{"cell_type":"code","execution_count":89,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch [   1 /  114]\n","Batch [   2 /  114]\n","Batch [   3 /  114]\n","Batch [   4 /  114]\n","Batch [   5 /  114]\n","Batch [   6 /  114]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 44\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBatch [\u001b[39m\u001b[39m%4d\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m%4d\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(valid_loader)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mpointcloud\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfloat(), data[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m outputs, __, __ \u001b[39m=\u001b[39m pointnet(inputs\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m all_preds \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(preds\u001b[39m.\u001b[39mnumpy())\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 44\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     xb, matrix3x3, matrix64x64 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(xb)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(xb))))\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 44\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m xb \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(torch\u001b[39m.\u001b[39mtranspose(\u001b[39minput\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m), matrix3x3)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(xb)))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m matrix64x64 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_transform(xb)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m xb \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(torch\u001b[39m.\u001b[39mtranspose(xb,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m), matrix64x64)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(xb)))\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/home/dmitry/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/notebooka1054845b4.ipynb –Ø—á–µ–π–∫–∞ 44\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m bs \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(\u001b[39minput\u001b[39m)))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(xb)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m xb \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(xb)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dmitry/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/ClassificationPointNet3D/notebooka1054845b4.ipynb#X60sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m pool \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMaxPool1d(xb\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))(xb)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","File \u001b[0;32m~/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ClassificationPointNet3D/conda_venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    307\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["pointnet.eval()\n","all_preds = []\n","all_labels = []\n","with torch.no_grad():\n","    for i, data in enumerate(valid_loader):\n","        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n","        \n","        inputs, labels = data['pointcloud'].float(), data['category']\n","        outputs, __, __ = pointnet(inputs.transpose(1,2))\n","        _, preds = torch.max(outputs.data, 1)\n","        all_preds += list(preds.numpy())\n","        all_labels += list(labels.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm = confusion_matrix(all_labels, all_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(8,8))\n","plot_confusion_matrix(cm, list(classes.keys()), normalize=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(8,8))\n","plot_confusion_matrix(cm, list(classes.keys()), normalize=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":943153,"sourceId":1598438,"sourceType":"datasetVersion"},{"sourceId":52279457,"sourceType":"kernelVersion"}],"dockerImageVersionId":30019,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
